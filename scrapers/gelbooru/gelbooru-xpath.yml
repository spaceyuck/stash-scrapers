name: gelbooru-xpath
# for gelbooru 0.2+
# https://github.com/stashapp/CommunityScrapers/issues/2273
# loosely based on danbooru

# intended to capture filename as produced by gallery-dl (rule34_<id>_<hash>.<ext>)
sceneByFragment: &fragementscraper
  action: scrapeXPath
  queryURL: "{filename}"
  queryURLReplace:
    filename:
      - regex: "[^a-zA-Z\\d\\-._~]" # clean filename so that it can construct a valid url
        with: ""
      - regex: "^gelbooru_(.*)" # map to domain by prefix
        with: "https://gelbooru.com/index.php?page=post&s=view&id=$1"
      - regex: "tbib_(.*)" # map to domain by prefix
        with: "https://tbib.org/index.php?page=post&s=view&id=$1"
      - regex: "^rule34_(.*)" # map to domain by prefix
        with: "https://rule34.xxx/index.php?page=post&s=view&id=$1"
      - regex: "^xbooru_(.*)" # map to domain by prefix
        with: "https://xbooru.com/post/show/$1"
      - regex: "^/safebooru_(.*)" # map to domain by prefix
        with: "https://safebooru.org/post/show/$1"
      - regex: "^/hypnohub_(.*)" # map to domain by prefix
        with: "https://hypnohub.net/post/show/$1"
      - regex: "^yandere_(.*)" # map to domain by prefix
        with: "https://yande.re/post/show/$1"
      - regex: '^(.*&id=)([0-9]+)_.*$' # capture numeric sequence at begining as ID
        with: "$1$2"
  scraper: postScraper
imageByFragment: *fragementscraper

sceneByURL:
  - action: scrapeXPath
    url: &urls
      - https://gelbooru.com
      - https://tbib.org
      - https://rule34.xxx
      - https://xbooru.com
      - https://safebooru.org
      - https://hypnohub.net
      - https://yande.re/post/show/
    scraper: postScraper
imageByURL:
  - action: scrapeXPath
    url: *urls
    scraper: postScraper

xPathScrapers:
  postScraper:
    image:
      # deviation from community version: keep title
      Title: &title
        selector: //title
        postProcess:
          - replace:
            # remove gelbooru title suffix
            - regex: '[ ]+-[ ]+Image View[ ]+-[ ]+\| Gelbooru.*$'
              with: ""
            # remove tbib title prefix
            - regex: '^The Big ImageBoard \(TBIB\)[ ]+-[ ]+(.*)[ ]+\|[ ]+[0-9]+$'
              with: "$1"
            # remove rule34 title of list page (redirect when unknown)
            - regex: '^The Big ImageBoard \(TBIB\)$'
              with: ""
            # remove rule34 title prefix
            - regex: '^Rule 34[ ]+-[ ]+(.*)[ ]+\|[ ]+[0-9]+$'
              with: "$1"
            # remove rule34 title of list page (redirect when unknown)
            - regex: '^Rule 34$'
              with: ""
            # remove xbooru title prefix
            - regex: '^Xbooru[ ]+-[ ]+(.*)[ ]+\|[ ]+[0-9]+$'
              with: "$1"
            # remove xbooru title of list page (redirect when unknown)
            - regex: '^Xbooru$'
              with: ""
            # remove safebooru title prefix
            - regex: '^Safebooru[ ]+-[ ]+(.*)[ ]+\|[ ]+[0-9]+$'
              with: "$1"
            # remove safebooru title of list page (redirect when unknown)
            - regex: '^Safebooru$'
              with: ""
            # remove hypnohub title prefix
            - regex: '^HypnoHub[ ]+-[ ]+(.*)[ ]+\|[ ]+[0-9]+$'
              with: "$1"
            # remove hypnohub title of list page (redirect when unknown)
            - regex: '^HypnoHub$'
              with: ""
            # remove yandere title prefix
            - regex: ' \| #[0-9]+ \| yande.re$'
              with: ""
      Date: &date
        selector: //div[@id="post-view" or @id="container"]//li[contains(text(),"Posted")]/text()[1]
        postProcess:
          - replace:
            - regex: 'Posted:'
              with: ""
            - regex: \d{2}:\d{2}:\d{2}$
              with: ""
          - parseDate: 2006-01-02
      Performers: &performers
        Name:
          selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-character")]/a[last()]/text()
      Studio: &artist
        Name: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-artist")]/a[last()]/text()
      Tags: &tag_string
        Name:
          # Variant A: only pull tags
          #selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-general")]/a[last()]/text()
          # Variant B: also pull metadata tags (like 2D, 3D)
          #selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-general") or contains(@class,"tag-type-metadata")]/a[last()]/text()
          # Variant C: also pull metadata tags (like 2D, 3D) and copyrights (source material names)
          selector: //div[@id="post-view" or @id="container"]//li[contains(@class,"tag-type-general") or contains(@class,"tag-type-metadata") or contains(@class,"tag-type-copyright")]/a[last()]/text()
      URLs: &source
        selector: '//div[@id="post-view" or @id="container"]//li[contains(text(),"Source:")]/a/@href'
      # pulls note overlay texts (translations) into Details box
      Details:
        selector: //div[@id="post-view" or @id="container"]//div[contains(@class,"note-body")]/text()
        concat: "\n"
    scene:
      Title: *title
      Date: *date
      Performers: *performers
      Studio: *artist
      Tags: *tag_string
      URLs: *source

driver:
  headers:
    - Key: User-Agent
      Value: stashapp/stash scraper

# Last Updated October 17, 2025
